{"cells":[{"cell_type":"markdown","metadata":{},"source":[" TODO: abstract of approach and key finidings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from helpers import *\n","#from prettify import *\n","pd.set_option('display.max_columns', 500)\n","\n","img_path = \"./Images/\""]},{"cell_type":"markdown","metadata":{},"source":[" #RQ4: home bias"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load the data\n","df = pickle_load('./Data/' + 'df_ba_ratings_filtered_beers_merged_users')\n","# define the treatment variable\n","df[\"treatment\"] = df.apply(lambda row: 1 if row[\"user_country\"] == row[\"beer_country\"] else 0, axis=1)"]},{"cell_type":"markdown","metadata":{},"source":[" ## data exploration for RQ4"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# feature number of reviews for each beer\n","df_groupby_beer = df.groupby(by = \"beer_id\").agg({\"beer_id\": \"count\", \"treatment\": \"sum\"})\n","df[\"nb_reviews_per_beer\"] = df.apply(lambda row: df_groupby_beer.loc[row[\"beer_id\"]][\"beer_id\"], axis=1)\n","df[\"nb_reviews_per_beer_local\"] = df.apply(lambda row: df_groupby_beer.loc[row[\"beer_id\"]][\"treatment\"], axis=1)\n","df[\"nb_reviews_per_beer_foreign\"] = df[\"nb_reviews_per_beer\"] - df[\"nb_reviews_per_beer_local\"]\n","df[\"share_local_reviews\"] = df[\"nb_reviews_per_beer_local\"] / df[\"nb_reviews_per_beer\"]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot the proportion of local reviews for each beer\n","groupby_beer = df.groupby(by=\"beer_id\").agg({\"share_local_reviews\": \"mean\"})\n","groupby_beer[\"share_local_reviews\"].hist(bins=50, label = \"all reviews\")\n","\n","# removing american reviews\n","groupby_beer_no_us = df[df[\"user_country\"] != \"United States\"].groupby(by=\"beer_id\").agg({\"share_local_reviews\": \"mean\"})\n","groupby_beer_no_us[\"share_local_reviews\"].hist(bins=50, label = \"non american reviews\")\n","plt.title(\"share of local reviews per beer\")\n","plt.legend()"]},{"cell_type":"markdown","metadata":{},"source":[" Comment on the figure above: It makes sense. most of the users are concentrated in the us. Therefore a beer from the us is mostly rated by locals and an beer with few user in this country mostly receives foreign reviews."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# how many beers do have a balance distribution ? (10-90%)\n","groupby_beer_no_us[(groupby_beer_no_us[\"share_local_reviews\"] > 0.1) & (groupby_beer_no_us[\"share_local_reviews\"] < 0.9)][\"share_local_reviews\"].hist()\n","plt.title(\"zoom on beers with balanced distribution of local and foreign reviews\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":[" # analysis without any matching"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot the rating distribution of the treatment and control groups prior to matching\n","df[df[\"treatment\"] == 1][\"rating\"].hist(bins=20, alpha=0.5, label=\"local reviews\")\n","df[df[\"treatment\"] == 0][\"rating\"].hist(bins=20, alpha=0.5, label=\"foreign reviews\")\n","plt.legend()\n","plt.title(\"distribution of local vs. foreign reviews\")\n","plt.show()\n","# run a t-test to see if there is a significant difference in ratings between reviews with treatment = 1 and reviews with treatment = 0 (prior to matching)\n","from scipy.stats import ttest_ind\n","res = ttest_ind(df[df[\"treatment\"] == 1][\"rating\"], df[df[\"treatment\"] == 0][\"rating\"], equal_var=False)\n","# print results of the t-test\n","print(\"t-test on the mean ratings of local and foreign reviews:\")\n","print(\"t-statistic: \", res[0])\n","print(\"p-value: \", res[1])\n","print(\"average difference of mean ratings between treatment and control\", df[df[\"treatment\"] == 1][\"rating\"].mean() - df[df[\"treatment\"] == 0][\"rating\"].mean())\n","\n","# now if we subset to beer with at least 10% of foreign reviews and 10% of local reviews\n","df_balanced = df[(df[\"share_local_reviews\"] > 0.1) & (df[\"share_local_reviews\"] < 0.9)]\n","df_balanced[df_balanced[\"treatment\"] == 1][\"rating\"].hist(bins=20, alpha=0.5, label=\"local reviews\")\n","df_balanced[df_balanced[\"treatment\"] == 0][\"rating\"].hist(bins=20, alpha=0.5, label=\"foreign reviews\")\n","plt.title(\"same for beers with balanced distribution of local and foreign reviews\")\n","plt.show()\n","\n","# run t-test\n","res = ttest_ind(df_balanced[df_balanced[\"treatment\"] == 1][\"rating\"], df_balanced[df_balanced[\"treatment\"] == 0][\"rating\"], equal_var=False)\n","print(\"t-test on the mean ratings of local and foreign reviews:\")\n","print(\"t-statistic: \", res[0])\n","print(\"p-value: \", res[1])\n","print(\"average difference of mean ratings between treatment and control\", df_balanced[df_balanced[\"treatment\"] == 1][\"rating\"].mean() - df_balanced[df_balanced[\"treatment\"] == 0][\"rating\"].mean())"]},{"cell_type":"markdown","metadata":{},"source":[" comments on the analysis: The result seem to show some significance in the bias. However, as seen in the previous, the huge imbalances in the dataset lead to a lot of beer with either only local reviews or only foreign reviews. Therefore, we need to mitigate this imbalance in the dataset before running the analysis. However, if we subset only to beers with comparable amount of local and foreign reviews, the dataset will be too small to run a meaningful analysis. Therefor, we will try propensity score matching method to balance the dataset."]},{"cell_type":"markdown","metadata":{},"source":[" ## propensity score matching"]},{"cell_type":"markdown","metadata":{},"source":[" ### propensity score calculcation using random forest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# add feature of average ratings given by the user\n","df_users = df.groupby(by = \"user_id\").agg({\"rating\": \"mean\"})\n","df[\"avg_user_rating\"] = df.apply(lambda row: df_users.loc[row[\"user_id\"]][\"rating\"], axis=1)\n","\n","# categories the style class\n","df[\"style_class_cat\"] = df[\"style_class\"].astype(\"category\").cat.codes"]},{"cell_type":"markdown","metadata":{},"source":[" We create a feature vector using the following features:\n"," - avg user rating\n"," - number of reviews\n"," - beer style class\n"," - beer average rating\n"," we cannot use user country and beer country beause they are already part of the treatment. Indeed, the classifier would then just have to check if they are equal or not to decide on the treatment/control group probabilities."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# feature list\n","feature_list = [\"avg_user_rating\", \"nbr_reviews\", \"style_class_cat\", \"avg_beer_rating\"]\n","\n","# why do we now have nans?\n","df = df.dropna(subset = \"avg_beer_rating\")\n","\n","X = df[feature_list].values\n","# create label vector (treatment column)\n","y = df[\"treatment\"].values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# split into train and test set\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score, confusion_matrix\n","\n","def random_forest_propensity(X, y):\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # train a random forest classifier\n","\n","    clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n","    clf.fit(X_train, y_train)\n","\n","    # get the probabilities on the test set\n","    y_pred = clf.predict_proba(X_test)[:,1]\n","    # predict the treatment with a threshold of 0.5\n","    y_pred_treated = clf.predict(X_test)\n","\n","    # measure f1 score\n","    print(\"f1 score: \", f1_score(y_test, y_pred_treated))\n","    # print confusion matrix\n","    print(confusion_matrix(y_test, y_pred_treated))\n","\n","    return y_pred\n","\n","y_pred = random_forest_propensity(X, y)"]},{"cell_type":"markdown","metadata":{},"source":[" comment on the results: Eventhough the f1 score looks high, the predictor is still shit. The predictor is very much biased toward predicting treatment = 1 because the dataset is very unbalanced.\n"," To better assess the quality of the mdel, we filter the review dataset to only keep countries with at least 1000 reviews (top 8 countries). We then balance our dataset by randomly sampling 1000 reviews per country."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["g = df.groupby(\"user_country\").count().sort_values(by=\"beer_id\", ascending=False)\n","# filter to countries in g with at least 1000 reviews\n","countries = g[g[\"beer_id\"] >= 1000].index\n","df_topcountries = df[df[\"user_country\"].isin(countries)] # 8 countries\n","g = df_topcountries.groupby(\"user_country\")\n","def sampling_k_elements(group, k=1000):\n","    if len(group) < k:\n","        return group\n","    return group.sample(k)\n","\n","df_topcountries_balanced = df_topcountries.groupby('user_country').apply(sampling_k_elements).reset_index(drop=True)\n","# check if we have 1000 reviews per country\n","df_topcountries_balanced.groupby(\"user_country\").count()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# check if random forest performance\n","X = df_topcountries_balanced[[\"avg_user_rating\", \"nbr_reviews\", \"style_class_cat\", \"avg_beer_rating\"]].values\n","# create label vector (treatment column)\n","y = df_topcountries_balanced[\"treatment\"].values\n","random_forest_propensity(X, y)\n","# random forest is still pretty shit"]},{"cell_type":"markdown","metadata":{},"source":[" ### matching using matrix factorization with biases vectors"]},{"cell_type":"markdown","metadata":{},"source":[" The motivation of the method is the following: some beers are arguably of better quality than others. Similarly some user are more critical in their ratings than others.\n","  If we want to isolate the effect of home bias on the rating, we should try to match reviews from the treatment and control groups which have similar beer quality and user criticism. We can retrieve those bias (for the users and the beers) using matrix factorization with biases. We then use those biases to match reviews between the treatment and control groups. The matching is done by minimizing the squared distance between the user biases of review (A, B) and the beer biases of review (A, B)\n"," citation (for MF with biases): https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# reset beer id and user id to be from 0 to nb_beer and nb_user\n","def reset_id(df, col):\n","    df[col] = df[col].astype(\"category\").cat.codes\n","    return df\n","\n","# Matrix factorization with biases\n","import surprise.prediction_algorithms.matrix_factorization as mf\n","from surprise import Reader, Dataset\n","\n","def get_biases(df, plot=False, verbose=False):\n","    df = reset_id(df, \"beer_id\")\n","    df = reset_id(df, \"user_id\")\n","\n","    algo = mf.SVD(n_factors=100, n_epochs=20, biased=True, lr_all=0.005, reg_all=0.02, verbose=verbose)\n","    reader = Reader(rating_scale=(1, 5))\n","    data = Dataset.load_from_df(df[[\"user_id\", \"beer_id\", \"rating\"]].rename(columns={\"user_id\": \"userID\", \"beer_id\": \"itemID\", \"rating\": \"rating\"}), reader)\n","    user_bias = algo.fit(data.build_full_trainset()).bu\n","    beer_bias = algo.fit(data.build_full_trainset()).bi\n","    if plot:\n","        plt.hist(user_bias, bins = 100)\n","        plt.hist(beer_bias, bins = 100)\n","        plt.show()\n","    df[\"user_bias\"] = df.apply(lambda row: user_bias[row[\"user_id\"]], axis=1)\n","    df[\"beer_bias\"] = df.apply(lambda row: beer_bias[row[\"beer_id\"]], axis=1)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = get_biases(df, plot=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# reset index reviews\n","df = df.reset_index()\n","df[\"idx\"] = df.index"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_sample = df.sample(frac = 0.002)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import networkx as nx\n","B = nx.Graph()\n","# Add nodes with the node attribute \"bipartite\"\n","B.add_nodes_from(df_sample[df_sample[\"treatment\"] == 0][\"idx\"], bipartite=0)\n","B.add_nodes_from(df_sample[df_sample[\"treatment\"] == 1][\"idx\"], bipartite=1)\n","print(B)\n","# Add edge between nodes of opposite node sets. The weights are the difference in user_bias squared plus the difference in beer_bias squared\n","control_nodes = {n for n, d in B.nodes(data=True) if d[\"bipartite\"] == 0}\n","treatment_nodes = set(B) - control_nodes\n","for control in control_nodes:\n","    for treatment in treatment_nodes:\n","        B.add_edge(control, treatment, weight=(df_sample.loc[control][\"user_bias\"] - df_sample.loc[treatment][\"user_bias\"])**2 + (df_sample.loc[control][\"beer_bias\"] - df_sample.loc[treatment][\"beer_bias\"])**2)\n","\n","# TODO: find an algorithm which is not O(n^2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# find minimum weight matching of the graph\n","matching = nx.bipartite.minimum_weight_full_matching(B, top_nodes = control_nodes)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# the key-value pair in matching appear twice, so we remove from matching all keys which are in the treatment group\n","matching = {k: v for k, v in matching.items() if k in control_nodes}\n","# print intersection of matching keys and values\n","print(set(matching.keys()) & set(matching.values()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get the ids of the reviews in the treatment and control groups\n","control_ids = [k for k, v in matching.items()]\n","treatment_ids = [v for k, v in matching.items()]\n","# create a new df with the matching\n","df_control = df_sample.loc[control_ids]\n","df_treatment = df_sample.loc[treatment_ids]\n","\n","# run a t-test on rating with the matching dataframe\n","res = ttest_ind(df_control[\"rating\"], df_treatment[\"rating\"])\n","print(res)\n","# after matching the result is not significative anymore\n","# TODO: verify with bigger sample size\n","# comput the difference of mean rating between control and treatment\n","print(df_treatment[\"rating\"].mean() - df_control[\"rating\"].mean())\n","\n","#plot the distribution of rating for the matching\n","plt.hist(df_treatment[\"rating\"], alpha=0.5, label=\"treatment\", bins=25)\n","plt.hist(df_control[\"rating\"], alpha=0.5, label=\"control\", bins=25)\n","plt.legend()\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" ### Matrix factorization: nearest neighbour\n"," create control treatment pairs where the user bias are close (within a bin of width epsilon)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2D hexagonal heat map plot of user bias and beer bias for treatment and control groups\n","user_bias, beer_bias = get_biases(df, plot=True)\n","df[\"user_bias\"] = df.apply(lambda row: user_bias[row[\"user_id\"]], axis=1)\n","df[\"beer_bias\"] = df.apply(lambda row: beer_bias[row[\"beer_id\"]], axis=1)\n","plt.hexbin(df[df[\"treatment\"] == 0][\"user_bias\"], df[df[\"treatment\"] == 0][\"beer_bias\"], bins = 'log', gridsize=25, label=\"control\", alpha=0.5)\n","plt.hexbin(df[df[\"treatment\"] == 1][\"user_bias\"], df[df[\"treatment\"] == 1][\"beer_bias\"], bins = 'log', gridsize=25, label=\"treatment\", alpha=0.5)\n","plt.xlabel(\"user bias\")\n","plt.ylabel(\"beer bias\")\n","plt.legend()\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 2D hexagonal heat map plot of user log bias and beer log bias for treatment and control groups\n","plt.hexbin(df[df[\"treatment\"] == 0][\"user_bias_log\"], df[df[\"treatment\"] == 0][\"beer_bias_log\"], bins = 'log', gridsize=25, label=\"control\", alpha=0.5)\n","plt.hexbin(df[df[\"treatment\"] == 1][\"user_bias_log\"], df[df[\"treatment\"] == 1][\"beer_bias_log\"], bins = 'log', gridsize=25, label=\"treatment\", alpha=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# discretize user bias and beer bias in 20 bins each\n","def balance(row):\n","    treatment = row[row[\"treatment\"] == 1]\n","    control = row[row[\"treatment\"] == 0]\n","    if len(treatment) > len(control):\n","        treatment = treatment.sample(len(control), random_state=42)\n","    else:\n","        control = control.sample(len(treatment), random_state=42)\n","    return pd.concat([treatment, control])\n","\n","# create a new column with the log of bias (we add one to deal with the case where the bias is 0)\n","def log_bias(df):\n","    df[\"user_bias_log\"] = df[\"user_bias\"].apply(lambda x: np.log(x+1))\n","    df[\"beer_bias_log\"] = df[\"beer_bias\"].apply(lambda x: np.log(x+1))\n","    return df\n","\n","def discretized_matching(df, method = \"equal_frequency\", column1=\"user_bias\", column2=\"beer_bias\", bins=20):\n","    pd.options.mode.chained_assignment = None  # default='warn'\n","    if method == \"equal_frequency\":\n","        df[\"user_bias_discretized\"] = pd.qcut(df[column1], bins, labels=False, duplicates='drop')\n","        df[\"beer_bias_discretized\"] = pd.qcut(df[column2], bins, labels=False, duplicates='drop')\n","    elif method == \"equal_width\":\n","        df[\"user_bias_discretized\"] = pd.cut(df[column1], bins, labels=False)\n","        df[\"beer_bias_discretized\"] = pd.cut(df[column2], bins, labels=False)\n","    elif method == \"log_equal_frequency\":\n","        df = log_bias(df)\n","        df[\"user_bias_discretized\"] = pd.qcut(df[column1 + \"_log\"], bins, labels=False)\n","        df[\"beer_bias_discretized\"] = pd.qcut(df[column2 + \"_log\"], bins, labels=False)\n","    elif method == \"log_equal_width\":\n","        df = log_bias(df)\n","        df[\"user_bias_discretized\"] = pd.cut(df[column1 + \"_log\"], bins, labels=False)\n","        df[\"beer_bias_discretized\"] = pd.cut(df[column2 + \"_log\"], bins, labels=False)\n","    else:\n","        raise ValueError(\"method not supported\")\n","    df_balanced = df.groupby([\"user_bias_discretized\", \"beer_bias_discretized\"]).apply(lambda x: balance(x)).reset_index(drop=True)\n","    return df_balanced"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_balanced = discretized_matching(df, \"equal_frequency\",\"user_bias\", \"beer_bias\", bins = 20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# count per bin\n","df_balanced.groupby([\"user_bias_discretized\", \"beer_bias_discretized\"]).count()\n","# not equal frequency in 2D (but equal in 1D)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sanity check if there are the same number of reviews in treatment and control groups\n","df_balanced.groupby(\"treatment\").count()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# run a t-test on rating with the balanced dataframe\n","res = ttest_ind(df_balanced[df_balanced[\"treatment\"] == 0][\"rating\"], df_balanced[df_balanced[\"treatment\"] == 1][\"rating\"])\n","print(res)\n","# print difference of mean rating between control and treatment\n","print(df_balanced[df_balanced[\"treatment\"] == 1][\"rating\"].mean() - df_balanced[df_balanced[\"treatment\"] == 0][\"rating\"].mean())\n","\n","# plot histogram of rating for treatment and control groups\n","plt.hist(df_balanced[df_balanced[\"treatment\"] == 1][\"rating\"], label=\"local reviews\", alpha = 0.5, bins = 25, density = True)\n","plt.hist(df_balanced[df_balanced[\"treatment\"] == 0][\"rating\"], label=\"foreign reviews\", alpha = 0.5, bins = 25, density = True)\n","plt.xlabel(\"rating\")\n","plt.ylabel(\"density\")\n","# add a vertical line at the mean rating\n","plt.axvline(df_balanced[df_balanced[\"treatment\"] == 1][\"rating\"].mean(), color='b', linestyle='dashed', linewidth=1, label=\"mean rating local\")\n","plt.axvline(df_balanced[df_balanced[\"treatment\"] == 0][\"rating\"].mean(), color='orangered', linestyle='dashed', linewidth=1, label=\"mean rating foreign\")\n","plt.legend()\n","plt.savefig(\"rating_distribution.png\")\n","plt.title(\"Rating distribution\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# boostrapping function to get the confidence interval\n","# bootstrapping function\n","# input: dataset, nb of iterations\n","# output: sorted list of means, overal mean, 95% confidence interval\n","\n","def bootstrapping_function(treatment, control, level = 0.05, iterations = 1000):\n","    differences = []\n","    for i in range(iterations):\n","        treatment_sample = np.random.choice(treatment, size = len(treatment), replace = True)\n","        control_sample = np.random.choice(control, size = len(treatment), replace = True)\n","        differences.append(np.mean(treatment_sample) - np.mean(control_sample))\n","    \n","    differences.sort()\n","    return np.mean(differences), differences[int(np.ceil(level/2*iterations))], differences[int(np.floor(1-(level/2) * iterations))]\n","\n","N_BOOSTRAP = 1000 #number of time we boostrap each dataset (be careful with runtimes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["diff_user_mean, diff_user_low, diff_user_high = bootstrapping_function(df_balanced[\"rating\"].loc[df_balanced[\"treatment\"] == 1], df_balanced[\"rating\"].loc[df_balanced[\"treatment\"] == 0], level = 0.05)\n","\n","df_results = pd.DataFrame({\"diff_user_mean\": [diff_user_mean], \"diff_user_low\": [diff_user_low], \"diff_user_high\": [diff_user_high]})\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_results[\"err_low\"] = df_results[\"diff_user_mean\"] - df_results[\"diff_user_low\"]\n","df_results[\"err_high\"] = df_results[\"diff_user_high\"] - df_results[\"diff_user_mean\"]\n","fig, ax = plt.subplots()\n","plt.errorbar([i for i in range(len(df_results))], df_results[\"diff_user_mean\"].to_numpy(), yerr=df_results[[\"err_low\", \"err_high\"]].transpose().to_numpy(), barsabove=True, capsize = 5, fmt = '.b', label = \"mean (95% CI)\")\n","ax.axhline(0, 0, 1, linestyle = \"--\", color = \"k\", label = \"no difference\")\n","plt.legend()\n","plt.xticks([i for i in range(len(df_results))], [\"full dataset\"])\n","plt.ylabel(\"user local - foreign rating difference\")\n","plt.title(\"diference in user rating between local and foreign reviews\")\n","plt.savefig(img_path + \"user_bias_confidence_interval.png\")\n","plt.show()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" The difference of distribution of rating between local and foreign reviews is almost indistinguishable. However, looking at the 95% confidence intervall, the effect is still statistically significant. We can conclude that the local beers are rated higher than the foreign beers, but not by much."]},{"cell_type":"markdown","metadata":{},"source":[" ### Matrix factorization (ter): comparison of bias vectors between control and treatment groups"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_treatment = df_sample[df_sample[\"treatment\"] == 1]\n","df_control = df_sample[df_sample[\"treatment\"] == 0]\n","\n","# balance the number of reviews in the control and treatment groups\n","df_treatment = df_treatment.sample(n = 924)\n","df_control = df_control.sample(n = 924)\n","\n","user_bias_treatment, beer_bias_treatment = get_biases(df_treatment)\n","user_bias_control, beer_bias_control = get_biases(df_control)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plot the difference in bias vectors between control and treatment groups\n","plt.hist(user_bias_treatment, label=\"treatment\", alpha = 0.5, bins = 25)\n","plt.hist(user_bias_control, label=\"control\", alpha = 0.5, bins = 25)\n","plt.title(\"user bias\")\n","plt.legend()\n","plt.show()\n","plt.hist(beer_bias_treatment, label=\"treatment\", alpha = 0.5, bins = 25)\n","plt.hist(beer_bias_control, label=\"control\", alpha = 0.5, bins = 25)\n","plt.title(\"beer bias\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# run a t-test on the difference in bias vectors\n","res = ttest_ind(user_bias_treatment, user_bias_control)\n","print(res)\n","# print difference in mean\n","print(np.mean(user_bias_treatment) - np.mean(user_bias_control))\n","res = ttest_ind(beer_bias_treatment, beer_bias_control)\n","print(res)\n","print(np.mean(beer_bias_treatment) - np.mean(beer_bias_control))"]},{"cell_type":"markdown","metadata":{},"source":[" ### Matrix factorization: analysis per country:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["groupby_country = df.groupby(\"user_country\").count().sort_values(by=\"beer_id\", ascending=False)\n","topten_country = groupby_country.index[:10]\n","df_topcountries = df[df[\"user_country\"].isin(topten_country)]\n",""]},{"cell_type":"markdown","metadata":{},"source":[" since we are testing results for 10 countries, we need to correct for multiple testing. We will use the Sidak correction. The alpha value for the Sidak correction is $\\alpha = 1 - (1-0.05)^\\frac{1}{10} = 0.005 \\%$, which will use to correct for multiple testing."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sidak correct:\n","alpha_1 = 1-(1-0.05)**(1/10)\n","print(\"The alpha value for the sidak correction is: \", alpha_1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["list_results = []\n","for country in topten_country:\n","    df_country = df_topcountries[df_topcountries[\"user_country\"] == country].copy()\n","    print(f\"country: {country}, number of reviews: {len(df_country)}\")\n","    df_country = get_biases(df_country)\n","    df_country = discretized_matching(df_country, \"equal_frequency\", \"user_bias\", \"beer_bias\", bins = 10)\n","\n","    # run a t-test on rating with the balanced dataframe\n","    res = ttest_ind(df_country[df_country[\"treatment\"] == 1][\"rating\"], df_country[df_country[\"treatment\"] == 0][\"rating\"])\n","    print(f\"{country}: {res}\")\n","    # print difference of mean rating between control and treatment\n","    print(df_country[df_country[\"treatment\"] == 1][\"rating\"].mean() - df_country[df_country[\"treatment\"] == 0][\"rating\"].mean())\n","\n","    # compute confidence interval\n","    diff_user_mean, diff_user_low, diff_user_high = bootstrapping_function(df_country[\"rating\"].loc[df_country[\"treatment\"] == 1], df_country[\"rating\"].loc[df_country[\"treatment\"] == 0], level = alpha_1, iterations = 1000)\n","    #print(f\"mean: {diff_user_mean:0.04}, 95%CI: [{diff_user_low:0.04}, {diff_user_high:0.04}]\")\n","\n","    #append results to list in key-value pairs\n","    list_results.append({\"country\": country, \"diff_user_mean\": diff_user_mean, \"diff_user_low\": diff_user_low, \"diff_user_high\": diff_user_high})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_results = pd.DataFrame(list_results)\n","df_results[\"err_low\"] = df_results[\"diff_user_mean\"] - df_results[\"diff_user_low\"]\n","df_results[\"err_high\"] = df_results[\"diff_user_high\"] - df_results[\"diff_user_mean\"]\n","fig, ax = plt.subplots(figsize = (10, 5))\n","plt.errorbar([i for i in range(len(df_results))], df_results[\"diff_user_mean\"].to_numpy(), yerr=df_results[[\"err_low\", \"err_high\"]].transpose().to_numpy(), fmt = 'o', color = 'b', label = f\"mean ({(1 - alpha_1)*100:.3f}% CI)\")\n","ax.axhline(0, 0, 1, linestyle = \"--\", color = \"k\", label = \"no difference\")\n","plt.xticks([i for i in range(len(df_results))], topten_country)\n","plt.ylabel(\"diference in user average rating for local and foreign beers\")\n","plt.title(\"user local - foreign rating difference\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_results"]},{"cell_type":"markdown","metadata":{},"source":[" Developping the analysis per country revealed a form of simpson's paradoxe. Altough the general dataset seem to be biased towards local beers, when analysing per country bias, we notice that 8 of the top 10 countries are biased towards foreign beers. This effect was hidden in the global analysis because the dataset mostly consists of reviews from the US, which is slightly positively biased towards local beers.\n","\n"," While the best beer country is subjective, Belgium and US are widely considered as major beer countries according to this [top 13 best beer countries in the world](https://www.thrillist.com/drink/nation/the-best-beer-countries-in-the-world). Therefor, it makes sense that user from those countries are biased toward rating their local beer higher. However, this argument is limited because other countries such as England or the Netherlands are also famous beer countries but have a bias towards foreign beers.\n","\n"," Bias towards foreign products might also be a result of consumer cosmopolitanism, an effect which described by  “the extent to which a consumer (1) exhibits an open-mindedness towards foreign countries and cultures, (2) appreciates the diversity brought about by the availability of products from different national and cultural origins, and (3) is positively disposed towards consuming products from foreign countries.” This effect also contributs to self identity, ie. “[the] frame of reference by which individuals evaluate their self-worth.” according to [Balabanis, G., Stathopoulou, A., & Qiao, J. (2019). Favoritism Toward Foreign and Domestic Brands: A Comparison of Different Theoretical Explanations. Journal of International Marketing](https://openaccess.city.ac.uk/id/eprint/23521/)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}